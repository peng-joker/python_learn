{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3fJNTeRoqiPNS6R5bvgdb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PmwEulUpeSi","executionInfo":{"status":"ok","timestamp":1716986591969,"user_tz":-480,"elapsed":15118,"user":{"displayName":"李辉","userId":"12972001611808140221"}},"outputId":"ee0cd65b-bc7c-4ae1-97e6-414c6c713341","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.1)\n","Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.1)\n","Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n","Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.0.55)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.63)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n","Requirement already satisfied: uuid6<2025.0.0,>=2024.1.12 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2024.1.12)\n","Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.30.4)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.2.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"]}],"source":["pip install langchain langchain_community faiss-gpu langgraph langchain-openai"]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"],"metadata":{"id":"l3_Qka1WFJa0","executionInfo":{"status":"ok","timestamp":1716986609469,"user_tz":-480,"elapsed":8092,"user":{"displayName":"李辉","userId":"12972001611808140221"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain.tools.retriever import create_retriever_tool\n","from langgraph.prebuilt import chat_agent_executor\n","from langchain_openai import ChatOpenAI\n","from langchain_core.messages import HumanMessage\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","search = TavilySearchResults(max_results=2)\n","\n","# 加载网页内容\n","loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n","docs = loader.load()\n","# 分割文本\n","documents = RecursiveCharacterTextSplitter(\n","    chunk_size=1000, chunk_overlap=200\n",").split_documents(docs)\n","# 生成嵌入向量并存储在FAISS向量数据库中\n","vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n","retriever = vector.as_retriever()\n","retriever_tool = create_retriever_tool(\n","    retriever,\n","\"langsmith_search\",\n","\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",")\n","\n","tools = [search, retriever_tool]\n","\n","model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"],"metadata":{"id":"FDZx5_4fFtuD","executionInfo":{"status":"ok","timestamp":1716987178478,"user_tz":-480,"elapsed":3246,"user":{"displayName":"李辉","userId":"12972001611808140221"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_messages(\n","[\n","  (\"user\", \"{text}\")\n","]\n",")\n","parser = StrOutputParser()\n","model_with_tool=model.bind_tools(tools)\n","chain = prompt | model_with_tool | parser\n","chain.invoke({\"text\":\"hi\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mwIuqXvFYmZQ","executionInfo":{"status":"ok","timestamp":1716987199926,"user_tz":-480,"elapsed":1806,"user":{"displayName":"李辉","userId":"12972001611808140221"}},"outputId":"ab45e646-a13f-494d-9f7d-93a4860343a8"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello! How can I assist you today?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from langgraph.checkpoint.sqlite import SqliteSaver\n","memory = SqliteSaver.from_conn_string(\":memory:\")\n","agent_executor = chat_agent_executor.create_tool_calling_executor(\n","    model, tools, checkpointer=memory\n",")\n","config = {\"configurable\": {\"thread_id\": \"abc1234\"}}\n","response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"how can langsmith help with testing?\")]},config)\n","response[\"messages\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFTYqwAwGJqz","executionInfo":{"status":"ok","timestamp":1716987251463,"user_tz":-480,"elapsed":9319,"user":{"displayName":"李辉","userId":"12972001611808140221"}},"outputId":"064d73aa-c264-49ea-b61c-5d7bf3fa88e8"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='how can langsmith help with testing?', id='42f8ece5-2565-41bc-8cb5-e7a509bc51a7'),\n"," AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WNwDKIGRmfouNFHzbngoW0YO', 'function': {'arguments': '{\"query\":\"how can LangSmith help with testing\"}', 'name': 'langsmith_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 135, 'total_tokens': 156}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-eadc3621-84fb-493e-bd07-2bc66b6337ee-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing'}, 'id': 'call_WNwDKIGRmfouNFHzbngoW0YO'}]),\n"," ToolMessage(content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='963a3bad-036a-4dcc-8666-095327bb0e0e', tool_call_id='call_WNwDKIGRmfouNFHzbngoW0YO'),\n"," AIMessage(content='LangSmith can help with testing by providing a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith works independently, so the use of LangChain is not necessary. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export necessary variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and optionally `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith offers multiple ways to log traces. You can find detailed information in the documentation.\\n\\nLangSmith provides tools for creating datasets, examples, and evaluators for testing your applications. It allows you to evaluate the performance of your models and applications, ensuring they meet your requirements.', response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 842, 'total_tokens': 1060}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-94f62ed4-2f44-40d1-a1d0-b769ac3f95c3-0')]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"what was my last question?\")]},config)\n","response[\"messages\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kCa4uwDUwHw","executionInfo":{"status":"ok","timestamp":1716987264246,"user_tz":-480,"elapsed":2785,"user":{"displayName":"李辉","userId":"12972001611808140221"}},"outputId":"616a0b2c-e113-406e-d3a8-e3ab6dcc23ef"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='how can langsmith help with testing?', id='42f8ece5-2565-41bc-8cb5-e7a509bc51a7'),\n"," AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\":\"how can LangSmith help with testing\"}', 'name': 'langsmith_search'}, 'id': 'call_WNwDKIGRmfouNFHzbngoW0YO', 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'token_usage': {'completion_tokens': 21, 'prompt_tokens': 135, 'total_tokens': 156}}, id='run-eadc3621-84fb-493e-bd07-2bc66b6337ee-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing'}, 'id': 'call_WNwDKIGRmfouNFHzbngoW0YO'}]),\n"," ToolMessage(content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='963a3bad-036a-4dcc-8666-095327bb0e0e', tool_call_id='call_WNwDKIGRmfouNFHzbngoW0YO'),\n"," AIMessage(content='LangSmith can help with testing by providing a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith works independently, so the use of LangChain is not necessary. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export necessary variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and optionally `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith offers multiple ways to log traces. You can find detailed information in the documentation.\\n\\nLangSmith provides tools for creating datasets, examples, and evaluators for testing your applications. It allows you to evaluate the performance of your models and applications, ensuring they meet your requirements.', response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'token_usage': {'completion_tokens': 218, 'prompt_tokens': 842, 'total_tokens': 1060}}, id='run-94f62ed4-2f44-40d1-a1d0-b769ac3f95c3-0'),\n"," HumanMessage(content='what was my last question?', id='2eca279f-8f1f-426e-b2fb-083c36058223'),\n"," AIMessage(content='Your last question was \"how can LangSmith help with testing?\"', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 1073, 'total_tokens': 1087}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-accc058d-46c4-46e8-96c5-ff30bf9bf4c1-0')]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from langchain_core.callbacks import BaseCallbackHandler\n","from typing import Any, Dict, List\n","from langchain_core.outputs import LLMResult\n","from langchain_core.messages import BaseMessage\n","class LoggingHandler(BaseCallbackHandler):\n","    def on_chat_model_start(\n","        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n","    ) -> None:\n","        print(\"Chat model started\")\n","\n","    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n","        print(f\"Chat model ended, response: {response}\")\n","\n","    def on_chain_start(\n","        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n","    ) -> None:\n","        print(f\"Chain {serialized.get('name')} started\")\n","\n","    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n","        print(f\"Chain ended, outputs: {outputs}\")\n","callbacks = [LoggingHandler()]\n","config = {\"configurable\": {\"thread_id\": \"abc1234\"},\"callbacks\": callbacks}\n","response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"what was my last question?\")]}, config=config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUIiS7IOu0xZ","executionInfo":{"status":"ok","timestamp":1716987301102,"user_tz":-480,"elapsed":2094,"user":{"displayName":"李辉","userId":"12972001611808140221"}},"outputId":"cc15a687-af80-46e8-fb3f-2eba2712d812"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Chain LangGraph started\n","Chain None started\n","Chain ended, outputs: {'messages': [HumanMessage(content='what was my last question?')]}\n","Chain RunnableSequence started\n","Chain None started\n","Chat model started\n","Chat model ended, response: generations=[[ChatGeneration(text='Your last question was \"what was my last question?\"', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Your last question was \"what was my last question?\"', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5443d6a7-1fdb-4f61-836b-15859591a4c8-0'))]] llm_output={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None} run=None\n","Chain ended, outputs: {'messages': [AIMessage(content='Your last question was \"what was my last question?\"', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5443d6a7-1fdb-4f61-836b-15859591a4c8-0')]}\n","Chain None started\n","Chain ended, outputs: {'messages': [AIMessage(content='Your last question was \"what was my last question?\"', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5443d6a7-1fdb-4f61-836b-15859591a4c8-0')]}\n","Chain None started\n","Chain ended, outputs: end\n","Chain ended, outputs: {'messages': [AIMessage(content='Your last question was \"what was my last question?\"', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5443d6a7-1fdb-4f61-836b-15859591a4c8-0')]}\n","Chain ended, outputs: {'messages': [HumanMessage(content='how can langsmith help with testing?', id='42f8ece5-2565-41bc-8cb5-e7a509bc51a7'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\":\"how can LangSmith help with testing\"}', 'name': 'langsmith_search'}, 'id': 'call_WNwDKIGRmfouNFHzbngoW0YO', 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'token_usage': {'completion_tokens': 21, 'prompt_tokens': 135, 'total_tokens': 156}}, id='run-eadc3621-84fb-493e-bd07-2bc66b6337ee-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'how can LangSmith help with testing'}, 'id': 'call_WNwDKIGRmfouNFHzbngoW0YO'}]), ToolMessage(content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\n\\nscore: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:', name='langsmith_search', id='963a3bad-036a-4dcc-8666-095327bb0e0e', tool_call_id='call_WNwDKIGRmfouNFHzbngoW0YO'), AIMessage(content='LangSmith can help with testing by providing a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith works independently, so the use of LangChain is not necessary. Here are some steps to get started with LangSmith for testing:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export necessary variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and optionally `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith offers multiple ways to log traces. You can find detailed information in the documentation.\\n\\nLangSmith provides tools for creating datasets, examples, and evaluators for testing your applications. It allows you to evaluate the performance of your models and applications, ensuring they meet your requirements.', response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'token_usage': {'completion_tokens': 218, 'prompt_tokens': 842, 'total_tokens': 1060}}, id='run-94f62ed4-2f44-40d1-a1d0-b769ac3f95c3-0'), HumanMessage(content='what was my last question?', id='2eca279f-8f1f-426e-b2fb-083c36058223'), AIMessage(content='Your last question was \"how can LangSmith help with testing?\"', response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'token_usage': {'completion_tokens': 14, 'prompt_tokens': 1073, 'total_tokens': 1087}}, id='run-accc058d-46c4-46e8-96c5-ff30bf9bf4c1-0'), HumanMessage(content='what was my last question?', id='bc78914a-63be-4c53-bb0a-a11a5b401598'), AIMessage(content='Your last question was \"what was my last question?\"', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1100, 'total_tokens': 1112}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5443d6a7-1fdb-4f61-836b-15859591a4c8-0')]}\n"]}]}]}